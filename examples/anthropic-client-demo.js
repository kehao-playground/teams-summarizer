/**
 * Anthropic Claude Client Demo
 * 
 * Demonstrates the Anthropic Claude client functionality with sample transcript data.
 * This shows how the client integrates with the transcript formatter output.
 * 
 * Usage:
 *   node examples/anthropic-client-demo.js
 * 
 * Note: Requires valid Anthropic API key in environment variable ANTHROPIC_API_KEY
 */

const { AnthropicClient, DEFAULT_PROMPTS } = require('../src/api/anthropicClient');

// Sample formatted transcript (output from transcriptFormatter)
const sampleFormattedTranscript = {
  metadata: {
    participants: ['ç‹å°æ˜', 'æå°è¯', 'å¼µç¶“ç†'],
    duration: '01:15:30',
    language: 'zh-tw',
    totalEntries: 234,
    startTime: '00:00:00',
    endTime: '01:15:30'
  },
  content: `[00:05:00] ç‹å°æ˜: æˆ‘å€‘ä¾†è¨è«–é€™å€‹å­£åº¦çš„ç”¢å“é–‹ç™¼è¨ˆç•«ã€‚æ ¹æ“šå¸‚å ´èª¿ç ”ï¼Œæˆ‘å€‘éœ€è¦å°ˆæ³¨åœ¨ç”¨æˆ¶é«”é©—çš„æ”¹å–„ä¸Šã€‚

[00:05:30] æå°è¯: æˆ‘åŒæ„ç‹å°æ˜çš„çœ‹æ³•ã€‚ç‰¹åˆ¥æ˜¯åœ¨ç§»å‹•ç«¯çš„ä½¿ç”¨é«”é©—ï¼Œæˆ‘å€‘æ”¶åˆ°å¾ˆå¤šç”¨æˆ¶åé¥‹èªªä»‹é¢ä¸å¤ ç›´è§€ã€‚

[00:06:15] å¼µç¶“ç†: å¾ˆå¥½çš„è§€é»ã€‚é‚£éº¼æˆ‘å€‘ä¾†åˆ¶å®šå…·é«”çš„è¡Œå‹•è¨ˆç•«ã€‚é¦–å…ˆï¼Œæˆ‘å»ºè­°æˆ‘å€‘åœ¨ä¸‹é€±å®Œæˆç”¨æˆ¶ç ”ç©¶å ±å‘Šã€‚

[00:07:00] ç‹å°æ˜: å¥½çš„ï¼Œæˆ‘å¯ä»¥è² è²¬ç”¨æˆ¶ç ”ç©¶é€™éƒ¨åˆ†ã€‚é è¨ˆéœ€è¦ä¸€é€±æ™‚é–“ä¾†æ”¶é›†æ•¸æ“šå’Œåˆ†æã€‚

[00:07:30] æå°è¯: æˆ‘ä¾†è² è²¬æŠ€è¡“æ–¹æ¡ˆçš„è©•ä¼°ã€‚æˆ‘å€‘éœ€è¦è©•ä¼°ç¾æœ‰æ¶æ§‹æ˜¯å¦èƒ½æ”¯æŒæ–°çš„ç”¨æˆ¶é«”é©—æ”¹å–„ã€‚

[00:08:00] å¼µç¶“ç†: å¾ˆå¥½ã€‚é‚£éº¼æ™‚ç¨‹å®‰æ’æ˜¯ï¼šç‹å°æ˜è² è²¬ç”¨æˆ¶ç ”ç©¶ï¼ˆä¸€é€±ï¼‰ï¼Œæå°è¯è² è²¬æŠ€è¡“è©•ä¼°ï¼ˆå…©é€±ï¼‰ï¼Œç„¶å¾Œæˆ‘å€‘åœ¨æœˆåº•å‰åˆ¶å®šæœ€çµ‚å¯¦æ–½è¨ˆç•«ã€‚

[00:08:45] ç‹å°æ˜: é—œæ–¼é ç®—æ–¹é¢ï¼Œæˆ‘å€‘é ä¼°éœ€è¦é¡å¤–æŠ•å…¥å¤§ç´„20è¬å°å¹£åœ¨ç”¨æˆ¶é«”é©—é¡§å•å’Œå·¥å…·ä¸Šã€‚

[00:09:15] å¼µç¶“ç†: é ç®—çœ‹èµ·ä¾†åˆç†ã€‚æˆ‘æœƒå‘ä¸Šç´šç”³è«‹æ‰¹å‡†ã€‚å¤§å®¶é‚„æœ‰å…¶ä»–å•é¡Œå—ï¼Ÿ

[00:09:45] æå°è¯: æˆ‘æƒ³ç¢ºèªä¸€ä¸‹ï¼Œæ–°çš„ç”¨æˆ¶é«”é©—æ”¹å–„æ˜¯å¦åŒ…æ‹¬ç„¡éšœç¤™åŠŸèƒ½çš„å„ªåŒ–ï¼Ÿ

[00:10:00] å¼µç¶“ç†: éå¸¸å¥½çš„å•é¡Œã€‚æ˜¯çš„ï¼Œç„¡éšœç¤™åŠŸèƒ½æ‡‰è©²æ˜¯æˆ‘å€‘ç”¨æˆ¶é«”é©—æ”¹å–„çš„é‡è¦çµ„æˆéƒ¨åˆ†ã€‚è«‹åœ¨æŠ€è¡“è©•ä¼°ä¸­ä¸€ä½µè€ƒæ…®ã€‚

[00:10:30] ç‹å°æ˜: äº†è§£ã€‚é‚£æˆ‘å€‘ä¸‹é€±ä¸‰å†é–‹æœƒæª¢è¦–é€²åº¦å¦‚ä½•ï¼Ÿ

[00:10:45] å¼µç¶“ç†: å¥½çš„ï¼Œå°±å®šä¸‹é€±ä¸‰ä¸‹åˆ2é»ã€‚ä»Šå¤©çš„æœƒè­°å°±åˆ°é€™è£¡ï¼Œè¬è¬å¤§å®¶ã€‚`,
  sections: [
    {
      content: '[00:05:00] ç‹å°æ˜: æˆ‘å€‘ä¾†è¨è«–é€™å€‹å­£åº¦çš„ç”¢å“é–‹ç™¼è¨ˆç•«ã€‚æ ¹æ“šå¸‚å ´èª¿ç ”ï¼Œæˆ‘å€‘éœ€è¦å°ˆæ³¨åœ¨ç”¨æˆ¶é«”é©—çš„æ”¹å–„ä¸Šã€‚\n[00:05:30] æå°è¯: æˆ‘åŒæ„ç‹å°æ˜çš„çœ‹æ³•ã€‚ç‰¹åˆ¥æ˜¯åœ¨ç§»å‹•ç«¯çš„ä½¿ç”¨é«”é©—ï¼Œæˆ‘å€‘æ”¶åˆ°å¾ˆå¤šç”¨æˆ¶åé¥‹èªªä»‹é¢ä¸å¤ ç›´è§€ã€‚'
    },
    {
      content: '[00:06:15] å¼µç¶“ç†: å¾ˆå¥½çš„è§€é»ã€‚é‚£éº¼æˆ‘å€‘ä¾†åˆ¶å®šå…·é«”çš„è¡Œå‹•è¨ˆç•«ã€‚é¦–å…ˆï¼Œæˆ‘å»ºè­°æˆ‘å€‘åœ¨ä¸‹é€±å®Œæˆç”¨æˆ¶ç ”ç©¶å ±å‘Šã€‚\n[00:07:00] ç‹å°æ˜: å¥½çš„ï¼Œæˆ‘å¯ä»¥è² è²¬ç”¨æˆ¶ç ”ç©¶é€™éƒ¨åˆ†ã€‚é è¨ˆéœ€è¦ä¸€é€±æ™‚é–“ä¾†æ”¶é›†æ•¸æ“šå’Œåˆ†æã€‚'
    },
    {
      content: '[00:07:30] æå°è¯: æˆ‘ä¾†è² è²¬æŠ€è¡“æ–¹æ¡ˆçš„è©•ä¼°ã€‚æˆ‘å€‘éœ€è¦è©•ä¼°ç¾æœ‰æ¶æ§‹æ˜¯å¦èƒ½æ”¯æŒæ–°çš„ç”¨æˆ¶é«”é©—æ”¹å–„ã€‚\n[00:08:00] å¼µç¶“ç†: å¾ˆå¥½ã€‚é‚£éº¼æ™‚ç¨‹å®‰æ’æ˜¯ï¼šç‹å°æ˜è² è²¬ç”¨æˆ¶ç ”ç©¶ï¼ˆä¸€é€±ï¼‰ï¼Œæå°è¯è² è²¬æŠ€è¡“è©•ä¼°ï¼ˆå…©é€±ï¼‰ï¼Œç„¶å¾Œæˆ‘å€‘åœ¨æœˆåº•å‰åˆ¶å®šæœ€çµ‚å¯¦æ–½è¨ˆç•«ã€‚'
    }
  ]
};

// Demo functions
async function demonstrateAnthropicClient() {
  console.log('ğŸ¤– Anthropic Claude Client Demo');
  console.log('===============================\n');

  // Check for API key
  const apiKey = process.env.ANTHROPIC_API_KEY;
  if (!apiKey) {
    console.log('âŒ Missing Anthropic API key');
    console.log('Please set ANTHROPIC_API_KEY environment variable');
    console.log('Example: export ANTHROPIC_API_KEY=sk-ant-api03-your-key-here\n');
    
    // Continue with offline demo
    demonstrateOfflineFeatures();
    return;
  }

  try {
    const client = new AnthropicClient();
    
    console.log('1ï¸âƒ£ Initializing Anthropic Claude Client...');
    await client.initialize(apiKey);
    console.log('âœ… Client initialized successfully\n');

    console.log('2ï¸âƒ£ Testing available models...');
    const models = await client.getAvailableModels();
    console.log(`âœ… Found ${models.length} available models`);
    console.log('Available models:', models.map(m => `${m.name} (${m.contextWindow} tokens)`).join(', '));
    console.log('');

    console.log('3ï¸âƒ£ Analyzing sample transcript...');
    console.log('ğŸ“Š Transcript metadata:');
    console.log(`   - Participants: ${sampleFormattedTranscript.metadata.participants.join(', ')}`);
    console.log(`   - Duration: ${sampleFormattedTranscript.metadata.duration}`);
    console.log(`   - Language: ${sampleFormattedTranscript.metadata.language}`);
    console.log(`   - Total entries: ${sampleFormattedTranscript.metadata.totalEntries}\n`);

    // Test token estimation
    const estimatedTokens = client.estimateTokenCount(sampleFormattedTranscript.content);
    console.log(`ğŸ“ Estimated tokens: ${estimatedTokens}`);
    console.log(`ğŸ” Needs chunking: ${await client.checkTokenLimits(sampleFormattedTranscript, 'claude-3-5-sonnet-20241022')}\n`);

    console.log('4ï¸âƒ£ Generating summaries with different prompts...\n');

    // Test different prompt types
    const promptTypes = ['default', 'actionItems', 'technical'];
    
    for (const promptType of promptTypes) {
      console.log(`ğŸ¯ Generating ${promptType} summary...`);
      
      try {
        const summary = await client.generateSummary(sampleFormattedTranscript, {
          promptType: promptType,
          language: 'zh-TW',
          temperature: 0.3
        });

        console.log(`âœ… Summary generated (${summary.metadata.usage?.input_tokens || 'unknown'} input tokens)`);
        console.log(`ğŸ“ Processing time: ${summary.metadata.processingTime}ms`);
        console.log('ğŸ“„ Summary preview:');
        console.log('   ', summary.summary.split('\n')[0].substring(0, 100) + '...\n');
        
      } catch (error) {
        console.log(`âŒ Failed to generate ${promptType} summary:`, error.message, '\n');
      }
    }

    console.log('5ï¸âƒ£ Testing multi-language support...');
    
    const languages = ['en', 'zh-TW', 'ja'];
    for (const lang of languages) {
      console.log(`ğŸŒ Testing language: ${lang}`);
      const instruction = client.getLanguageInstruction(lang);
      console.log(`   Instruction: ${instruction}\n`);
    }

    console.log('ğŸ‰ Demo completed successfully!');

  } catch (error) {
    console.error('âŒ Demo failed:', error.message);
    console.error('Full error:', error);
  }
}

function demonstrateOfflineFeatures() {
  console.log('ğŸ”§ Offline Feature Demo');
  console.log('======================\n');

  const client = new AnthropicClient();

  console.log('1ï¸âƒ£ Testing API key validation...');
  const validKey = 'sk-ant-api03-test1234567890abcdef1234567890abcdef123456';
  const invalidKey = 'invalid-key';
  
  console.log(`âœ… Valid key format: ${client.validateApiKey(validKey)}`);
  console.log(`âŒ Invalid key format: ${client.validateApiKey(invalidKey)}\n`);

  console.log('2ï¸âƒ£ Testing token estimation...');
  const shortText = 'Hello world';
  const longText = sampleFormattedTranscript.content;
  
  console.log(`ğŸ“ Short text tokens: ${client.estimateTokenCount(shortText)}`);
  console.log(`ğŸ“ Long text tokens: ${client.estimateTokenCount(longText)}\n`);

  console.log('3ï¸âƒ£ Testing prompt building...');
  const systemPrompt = client.buildSystemPrompt('default', null, 'zh-TW');
  console.log('ğŸ¯ System prompt preview:');
  console.log('   ', systemPrompt.split('\n')[0].substring(0, 80) + '...\n');

  console.log('4ï¸âƒ£ Testing user message building...');
  const userMessage = client.buildUserMessage(sampleFormattedTranscript);
  console.log('ğŸ“ User message preview:');
  console.log('   ', userMessage.split('\n')[0] + '...\n');

  console.log('5ï¸âƒ£ Testing chunking strategy...');
  const chunks = client.createBasicChunks(sampleFormattedTranscript);
  console.log(`ğŸ”ª Created ${chunks.length} chunks`);
  console.log(`ğŸ“¦ First chunk preview: ${chunks[0].content.substring(0, 50)}...\n`);

  console.log('6ï¸âƒ£ Available prompts:');
  Object.keys(DEFAULT_PROMPTS).forEach(key => {
    console.log(`   - ${key}: ${DEFAULT_PROMPTS[key].split('\n')[0]}`);
  });

  console.log('\nğŸ‰ Offline demo completed!');
}

// Error handling demo
function demonstrateErrorHandling() {
  console.log('\nğŸš¨ Error Handling Demo');
  console.log('=====================\n');

  const client = new AnthropicClient();

  // Test error classification
  const errors = [
    new Error('401 Unauthorized'),
    new Error('429 Rate limit exceeded'),
    new Error('500 Internal Server Error'),
    new Error('Quota exceeded for current month')
  ];

  errors.forEach(error => {
    const shouldRetry = !client.shouldNotRetry(error);
    console.log(`ğŸ” Error: ${error.message}`);
    console.log(`   Should retry: ${shouldRetry ? 'âœ…' : 'âŒ'}\n`);
  });

  // Test detailed error creation
  const originalError = new Error('Sample error');
  const detailedError = client.createDetailedError(originalError);
  console.log('ğŸ“‹ Detailed error structure:');
  console.log(`   Name: ${detailedError.name}`);
  console.log(`   Message: ${detailedError.message}`);
  console.log(`   Timestamp: ${detailedError.timestamp}`);
  console.log(`   Has original error: ${!!detailedError.originalError}\n`);
}

// Integration demo
function demonstrateIntegration() {
  console.log('\nğŸ”— Integration Demo');
  console.log('==================\n');

  console.log('ğŸ“‹ This demo shows how Anthropic Claude Client integrates with:');
  console.log('   - Transcript Formatter (provides formatted input)');
  console.log('   - Storage Manager (provides API keys)');
  console.log('   - Popup UI (receives summary output)');
  console.log('   - Background Service Worker (orchestrates the flow)\n');

  console.log('ğŸ”„ Typical workflow:');
  console.log('   1. User clicks "Generate Summary" in popup');
  console.log('   2. Popup requests API key from Storage Manager');
  console.log('   3. Background worker initializes Anthropic Client');
  console.log('   4. Client receives formatted transcript');
  console.log('   5. Client calls Anthropic API with appropriate prompt');
  console.log('   6. Generated summary returned to popup for display\n');

  console.log('âš™ï¸ Configuration options:');
  console.log('   - Prompt type: default, actionItems, technical, custom');
  console.log('   - Output language: en, zh-TW, zh-CN, ja, ko, es, fr, de');
  console.log('   - Model: claude-3-5-sonnet-20241022 (default), claude-3-opus-20240229');
  console.log('   - Temperature: 0.0-1.0 (default: 0.3)');
  console.log('   - Max tokens: up to 8,192 for output\n');
}

// Performance testing demo
async function demonstratePerformance() {
  console.log('\nâš¡ Performance Demo');
  console.log('==================\n');

  const client = new AnthropicClient();

  console.log('ğŸ“Š Context window comparison:');
  console.log('   - Claude 3.5 Sonnet: 200,000 tokens');
  console.log('   - Claude 3 Opus: 200,000 tokens');
  console.log('   - Claude 3 Haiku: 200,000 tokens\n');

  console.log('ğŸ” Chunking analysis for sample transcript:');
  const estimatedTokens = client.estimateTokenCount(sampleFormattedTranscript.content);
  console.log(`   Estimated tokens: ${estimatedTokens}`);
  
  const models = ['claude-3-5-sonnet-20241022', 'claude-3-opus-20240229', 'claude-3-haiku-20240307'];
  for (const model of models) {
    const needsChunking = await client.checkTokenLimits(sampleFormattedTranscript, model);
    console.log(`   ${model}: ${needsChunking ? 'Needs chunking' : 'Single request'}`);
  }

  console.log('\nâ±ï¸ Rate limiting:');
  console.log('   - Exponential backoff on failures');
  console.log('   - Respects rate limit headers');
  console.log('   - Maximum 3 retries per request');
  console.log('   - 60 second timeout per request\n');
}

// Comparison with OpenAI demo
function demonstrateComparison() {
  console.log('\nğŸ”„ OpenAI vs Claude Comparison');
  console.log('==============================\n');

  const client = new AnthropicClient();

  console.log('ğŸ“ API Format Differences:');
  console.log('   OpenAI: Separate system and user messages');
  console.log('   Claude: Combined system + user in single message\n');

  console.log('ğŸ”‘ API Key Formats:');
  console.log('   OpenAI: sk-...');
  console.log('   Claude: sk-ant-api03-...\n');

  console.log('ğŸ—ï¸ Model Context Windows:');
  console.log('   GPT 4.1: 1,047,576 tokens (1M+)');
  console.log('   Claude 3.5 Sonnet: 200,000 tokens\n');

  console.log('ğŸ¯ Feature Parity:');
  console.log('   âœ… Same prompt templates');
  console.log('   âœ… Same language support');
  console.log('   âœ… Same chunking strategy');
  console.log('   âœ… Same error handling');
  console.log('   âœ… Same response format');
  console.log('   âœ… Same integration interface\n');

  console.log('ğŸŒŸ Claude-specific Advantages:');
  console.log('   - More recent training data (2024 vs 2023)');
  console.log('   - Better reasoning for complex topics');
  console.log('   - More nuanced understanding of context\n');

  console.log('ğŸŒŸ GPT 4.1-specific Advantages:');
  console.log('   - Much larger context window (1M+ vs 200k)');
  console.log('   - Better performance on certain tasks');
  console.log('   - More established API ecosystem\n');
}

// Main demo runner
async function runDemo() {
  console.clear();
  console.log('ğŸš€ Teams Transcript Extension - Anthropic Claude Client Demo\n');

  await demonstrateAnthropicClient();
  demonstrateOfflineFeatures();
  demonstrateErrorHandling();
  demonstrateIntegration();
  await demonstratePerformance();
  demonstrateComparison();

  console.log('\nğŸ“š Next steps:');
  console.log('   - Run unit tests: npm test -- anthropicClient.test.js');
  console.log('   - Set ANTHROPIC_API_KEY to test live API calls');
  console.log('   - Compare with OpenAI client performance');
  console.log('   - Check Task 10 for summary export functionality');
  console.log('   - See design.md for full integration details\n');
}

// Run the demo
if (require.main === module) {
  runDemo().catch(console.error);
}

module.exports = {
  demonstrateAnthropicClient,
  demonstrateOfflineFeatures,
  demonstrateComparison,
  sampleFormattedTranscript
};